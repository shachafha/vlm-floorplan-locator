{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "# put your OpenAI API key in the environment variable OPENAI_API_KEY\n",
    "api_key= os.getenv(\"OPENAI_API_KEY\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-01T17:43:55.670655Z",
     "start_time": "2025-06-01T17:43:55.665265Z"
    }
   },
   "id": "be97748649773fa8",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-01T17:43:57.172525Z",
     "start_time": "2025-06-01T17:43:57.139985Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_node_images(\n",
    "    images_folder: str,\n",
    "    prompt_file: str,\n",
    "    model_name: str = \"gpt-4o-mini\",\n",
    "    output_file: str = \"node_image_results.json\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Iterate over all JPG images in images_folder, send each image + prompt to the GPT vision model,\n",
    "    and save structured results to a JSON file.\n",
    "\n",
    "    images_folder:  Path to \"CEPSR - Floor 7/Node images\"\n",
    "    prompt_file:    Path to the text file containing your base prompt (extracting_image_data_prompt.txt)\n",
    "    model_name:     The vision-capable GPT model (e.g., \"gpt-4o-mini\")\n",
    "    output_file:    Filename to write the final JSON results\n",
    "    \"\"\"\n",
    "    # Initialize OpenAI client\n",
    "    client = OpenAI(api_key=api_key)  # Make sure OPENAI_API_KEY is set in environment\n",
    "    \n",
    "    # Read the base prompt from disk\n",
    "    with open(prompt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        base_prompt = f.read().strip()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Find all .JPG files inside images_folder\n",
    "    image_paths = glob.glob(os.path.join(images_folder, \"*.JPG\"))\n",
    "\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "            \n",
    "        basename = os.path.basename(img_path)                # e.g. \"node2_north.JPG\"\n",
    "        name_no_ext, ext = os.path.splitext(basename)         # e.g. (\"node2_north\", \".JPG\")\n",
    "        parts = name_no_ext.split(\"_\")\n",
    "        if len(parts) != 2 or not parts[0].startswith(\"node\"):\n",
    "            # Skip any file that does not match the pattern \"node{N}_{dir}.JPG\"\n",
    "            continue\n",
    "\n",
    "        # Extract numeric location and direction\n",
    "        try:\n",
    "            location_num = int(parts[0].replace(\"node\", \"\"))  # e.g. 2\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        direction = parts[1].lower()                         # e.g. \"north\", \"east\"\n",
    "\n",
    "        # Option 1: Resize image to reduce costs (uncomment if needed)\n",
    "        # from PIL import Image\n",
    "        # with Image.open(img_path) as img:\n",
    "        #     img.thumbnail((1024, 1024))  # Resize to max 1024x1024\n",
    "        #     img_byte_arr = io.BytesIO()\n",
    "        #     img.save(img_byte_arr, format='JPEG', quality=85)\n",
    "        #     image_data = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        \n",
    "        # Option 2: Use original image (current approach)\n",
    "        with open(img_path, \"rb\") as image_file:\n",
    "            image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "        # Build the user message with the image\n",
    "        user_content = f\"{base_prompt}\\n\\nImage filename: {basename}\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": user_content\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{image_data}\"\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "           # Extract the response content\n",
    "            raw_response = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Parse JSON from the response\n",
    "            try:\n",
    "                # Remove markdown code blocks if present\n",
    "                if raw_response.startswith('```json'):\n",
    "                    # Extract JSON between ```json and ```\n",
    "                    json_start = raw_response.find('```json') + 7\n",
    "                    json_end = raw_response.rfind('```')\n",
    "                    json_str = raw_response[json_start:json_end].strip()\n",
    "                elif raw_response.startswith('```'):\n",
    "                    # Extract JSON between ``` and ```\n",
    "                    json_start = raw_response.find('```') + 3\n",
    "                    json_end = raw_response.rfind('```')\n",
    "                    json_str = raw_response[json_start:json_end].strip()\n",
    "                else:\n",
    "                    # Assume the entire response is JSON\n",
    "                    json_str = raw_response\n",
    "                \n",
    "                # Parse the JSON string into a Python object\n",
    "                parsed_json = json.loads(json_str)\n",
    "                description = parsed_json  # Store as actual JSON object\n",
    "                \n",
    "            except json.JSONDecodeError as json_err:\n",
    "                print(f\"Warning: Could not parse JSON from {basename}: {json_err}\")\n",
    "                print(f\"Raw response: {raw_response[:200]}...\")\n",
    "                # Fallback to storing as text if JSON parsing fails\n",
    "                description = raw_response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {basename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Collect this into our results list\n",
    "        results.append({\n",
    "            \"location\":    location_num,\n",
    "            \"direction\":   direction,\n",
    "            \"description\": description,\n",
    "            \"filename\":    basename\n",
    "        })\n",
    "\n",
    "        print(f\"Processed {basename} (location {location_num}, {direction})\")\n",
    "\n",
    "    # Write the results array to disk in JSON format\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        json.dump(results, out_f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Finished. Results saved to {output_file}. Processed {len(results)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed node3_east.JPG (location 3, east)\n",
      "Processed node2_east.JPG (location 2, east)\n",
      "Processed node10_north.JPG (location 10, north)\n",
      "Processed node1_south.JPG (location 1, south)\n",
      "Processed node5_west.JPG (location 5, west)\n",
      "Processed node4_west.JPG (location 4, west)\n",
      "Processed node9_east.JPG (location 9, east)\n",
      "Processed node8_east.JPG (location 8, east)\n",
      "Processed node11_south.JPG (location 11, south)\n",
      "Processed node7_south.JPG (location 7, south)\n",
      "Processed node12_west.JPG (location 12, west)\n",
      "Processed node6_north.JPG (location 6, north)\n",
      "Processed node11_north.JPG (location 11, north)\n",
      "Processed node1_north.JPG (location 1, north)\n",
      "Processed node10_south.JPG (location 10, south)\n",
      "Processed node12_east.JPG (location 12, east)\n",
      "Processed node4_east.JPG (location 4, east)\n",
      "Processed node6_south.JPG (location 6, south)\n",
      "Processed node5_east.JPG (location 5, east)\n",
      "Processed node2_west.JPG (location 2, west)\n",
      "Processed node3_west.JPG (location 3, west)\n",
      "Processed node7_north.JPG (location 7, north)\n",
      "Processed node8_west.JPG (location 8, west)\n",
      "Processed node9_west.JPG (location 9, west)\n",
      "Processed node12_north.JPG (location 12, north)\n",
      "Processed node3_south.JPG (location 3, south)\n",
      "Processed node10_west.JPG (location 10, west)\n",
      "Processed node11_west.JPG (location 11, west)\n",
      "Processed node2_north.JPG (location 2, north)\n",
      "Processed node5_south.JPG (location 5, south)\n",
      "Processed node9_north.JPG (location 9, north)\n",
      "Processed node1_east.JPG (location 1, east)\n",
      "Processed node8_south.JPG (location 8, south)\n",
      "Processed node6_west.JPG (location 6, west)\n",
      "Processed node4_north.JPG (location 4, north)\n",
      "Processed node7_west.JPG (location 7, west)\n",
      "Processed node2_south.JPG (location 2, south)\n",
      "Processed node3_north.JPG (location 3, north)\n",
      "Processed node12_south.JPG (location 12, south)\n",
      "Processed node7_east.JPG (location 7, east)\n",
      "Processed node6_east.JPG (location 6, east)\n",
      "Processed node1_west.JPG (location 1, west)\n",
      "Processed node8_north.JPG (location 8, north)\n",
      "Processed node4_south.JPG (location 4, south)\n",
      "Processed node11_east.JPG (location 11, east)\n",
      "Processed node10_east.JPG (location 10, east)\n",
      "Processed node5_north.JPG (location 5, north)\n",
      "Processed node9_south.JPG (location 9, south)\n",
      "Finished. Results saved to node_image_results.json. Processed 48 images.\n"
     ]
    }
   ],
   "source": [
    "images_folder = \"CEPSR - Floor 7/Node images\"\n",
    "prompt_file = \"extracting_image_data_prompt.txt\"\n",
    "process_node_images(images_folder, prompt_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-01T17:51:31.053501Z",
     "start_time": "2025-06-01T17:44:00.047638Z"
    }
   },
   "id": "2ca6b8a13d5addd7",
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
